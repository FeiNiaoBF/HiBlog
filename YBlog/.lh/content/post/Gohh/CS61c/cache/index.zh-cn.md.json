{
    "sourceFile": "content/post/Gohh/CS61c/cache/index.zh-cn.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 6,
            "patches": [
                {
                    "date": 1715560768088,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1715560774389,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,4 +9,139 @@\n weight:\n math: false\n readingTime: true\n ---\n+\n+\n+*资料来源: cs 61 c*\n+\n+> Cache 可以说是计算机技术革命中最伟大的想法了\n+\n+想一个问题：在我们的电脑里，指令是怎么控制内存里的东西的？因为我们要运行电脑除了 CPU 以外我们要向外 `拿取` 数据才能执行一系列的指令，这样电脑才算运行起来。\n+\n+让我们来看下面的这张图，这是十分完整的计算机组成结构：\n+\n+##  Components of a Computer\n+\n+![Components of a Computer](https://s2.loli.net/2023/04/24/Fzb3uHQBLTlqOgD.png)\n+\n+我们可以从中看到在 CPU 需要运行一个进程的时候，首先会将指令告诉主存（main memory）, 然后开始在主存中找地址（Address）找到后加载到在 CPU 内部通用寄存器（register）然后开始执行\n+执行完后再写入主存中。\n+> 在这里面还有一个步骤，memory 要先向 disk 中读取数据\n+\n+其实现实中，CPU 通用寄存器的速度和主存之间存在着太大的差异。两者之间的速度大致如下关系：\n+![memory-steep](https://s2.loli.net/2023/04/24/KtvMSR7QmrXpjbl.png)\n+\n+Oh!!! 它们相差 1,000 倍左右，这是无法想像的，就比如当我前 1 ns 的时候 CPU 已经做完了，而我还要等 1000 ns 的 memory 的时间，因此在我们看来 CPU 此时是空闲的，大大的浪费了。\n+\n+因此，如果我们可以提升主存的速度，那么对于系统来说将会获得很大的性能提升。但我们试图提升主存的速度和容量，又期望其成本很低，这就有点难为人了。因此，我们有一种折中的方法，那就是制作一块速度极快但是容量极小的存储设备。那么其成本也不会太高。这块存储设备我们称之为 `cache`。在硬件上，我们将 `cache` 放置在 `CPU` 和 `主存` 之间，作为主存数据的缓存。当 CPU 试图从主存中 load/store 数据的时候， CPU 会首先从 cache 中查找对应地址的数据是否缓存在 cache 中。如果其数据缓存在 cache 中，直接从 cache 中拿到数据并返回给 CPU。\n+\n+![add-cache.png](https://s2.loli.net/2023/04/24/qLhOmsTV2IE9S8p.png)\n+\n+\n+其实类比的话，我蛮喜欢 CS 61 c 里面的 Library Analogy，而我自己的想法是有点像现在的物流运输：对一些物品都有一个 `主要的仓库`，而也有一些 `本地仓`，当我要送东西的时候我先去看看 `本地仓` 有没有，没有就再去 `主仓` 去看看，但时间上就没有本地仓的快\n+\n+> [[2. Areas/01 Blog/03-ComputerSystems/cs61c/SRAM vs. DRAM vs. Disk]]\n+\n+## Memory Hierarchy\n+\n+好的现在我们知道了 `cache` 的出现了，而下面的图是说明了对于不同的内存级别\n+![Cache-line.png](https://s2.loli.net/2023/04/24/3anw1UgNoWDZBsq.png)\n+\n+## Cache\n+\n+### Cache 的级别\n+> 每一级的 cache 就是每一个下级内存的副本\n+\n+Cahe 的速度在一定程度上同样影响着系统的性能. 当 cache 中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中 load 数据。为了进一步提升性能，引入多级 cache。前面提到的 cache，称之为 L 1 cache（第一级 cache）。我们在 L 1 cache 后面连接 L 2 cache，在 L 2 cache 和主存之间连接 L 3 cache。等级越高，速度越慢，容量越大。\n+\n+### Temporal Locality (时间局部性)\n+> If a memory location is referenced then it will tend to be referenced again soon\n+\n+比如说我用过一次这个地址, 我保存起来以防我下次使用\n+\n+### Spatial Locality (空间局部性)\n+> If a memory location is referenced, the locations with nearby addresses will\n+   Tend to be referenced soon\n+\n+比如一个数组，在我读取的时候它会把数组左右的都读取了\n+\n+### Cache Hit vs Cache Miss\n+\n+在我要对数据进行查找的时候会出现两种情况 `Cache Hit` & `Cache Miss`.\n+\n+#### Cache hit\n+你要查找的数据 `在缓存中` 从缓存中检索数据并将其带到处理器.\n+\n+#### Cache miss\n+你要查找的数据 `不在缓存中` 去内存中找数据，把数据放到缓存中，带到处理器中\n+\n+## Cache 的工作原理\n+\n+现在我们来继续说一些快取的工作原理, 在此之前先来说一下的一些名词\n+\t什么是 `line/tag/index/offset/valid`\n+\n+- **line:** 我们将 cache 平均分成相等的很多块，每一个块大小称之为 `cache line` 也可以叫 `cache block`，其大小是 `cache line size`。\n+- **tag:** Used to identify the data (用于识别数据)。每条 Cache Line 前都会有一个独立分配的内存来存 tag，其就是内存地址的前 Nbits。\n+$$ addressbits -  offsetbits $$\n+- **offset:** Identifies the byte offset (标识字节偏移量)。一般是低位后几位。\n+$$ offset = log_2(line size) $$\n+- **index:** 内存地址后续的 bits 则是在这--Way 的是 Cache Line 索引，可以索引 Cache Line。\n+- **Valid bit:** Tells you if the data stored at a given cache line is valid (告诉您存储在给定缓存行中的数据是否有效)\n+\n+\n+> 一个地址访问要映射到 Cache 中，地址被分成三个字段：tag，set index, block offset。这样，通过一个物理地址就可以获取数据或指令在缓存中的位置 (set, way, byte))\n+\n+\n+![line-block.png](https://s2.loli.net/2023/04/24/mHdMoveGWXkiNL4.png)\n+\n+### Direct mapped cache (直接映射缓存)\n+\n+优点：直接映射缓存在硬件设计上会更加简单，因此成本上也会较低。\n+> 一句话, 我一个个的加载进入 cache, 当我的 cache 满了我就转头再来一遍\n+\n+>只适合于**大容量**Cache\n+\n+缺点: 继续访问下面的地址时，依然会 cache 缺失。这就相当于每次访问数据都要从主存中读取，所以 cache 的存在并没有对性能提升有效, 有 `cache颠簸` (每个主存块只有一个固定位置可存放，容易产生冲突)\n+\n+![Direct Mapped.png](https://s2.loli.net/2023/04/24/xeav7mlIDAyOwqK.png)\n+\n+![Direct Mapped-cache.png](https://s2.loli.net/2023/04/24/4EYI7Va1S5lKgow.png)\n+\n+### Two-way set associative cache (两路组相连缓存)\n+**Cache 分了 2 组**\n+\n+优点: 减少 cache 颠簸出现频率\n+> 组相联映射实际上是直接映射和全相联映射的折中方案\n+\n+缺点: 增加硬件设计复杂读、成本较高 (需要比较多个 cache line 的 TAG)\n+\n+![set associative-cache.png](https://s2.loli.net/2023/04/24/yXE8J6RMo9F3Vxq.png)\n+\n+\n+### Fully Associative Cache (全相连缓存)\n+\n+优点: 最大程度的降低 cache 颠簸的频率\n+>只适合于**小容量**Cache\n+\n+缺点: 增加硬件设计复杂读、成本较高 (需要比较多个 cache line 的 TAG)\n+\n+扩展：[[More Eviction Policies]]\n+![](https://s2.loli.net/2023/07/10/TRUdXNBPsveZS7D.png)\n+\n+\n+![Fully Associative.png](https://s2.loli.net/2023/04/24/76uSATyrPno1eYf.png)\n+\n+寻找 Hit 的电路\n+\n+![Required to Check for Hit](https://s2.loli.net/2023/04/24/3VYzGo9dkgHwcrS.png)\n+\n+[[Types of Misses]]\n+\n+![](https://s2.loli.net/2023/04/24/M4Fc1g6k5OrfBpj.png)\n+\n+### Comparisons\n+\n+三个 cache 的区别之分\n+![Comparisons](https://s2.loli.net/2023/04/24/iICnWkpOMcFtKZH.png)\n+**需补充**\n+\n"
                },
                {
                    "date": 1715560781438,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,9 +19,9 @@\n 想一个问题：在我们的电脑里，指令是怎么控制内存里的东西的？因为我们要运行电脑除了 CPU 以外我们要向外 `拿取` 数据才能执行一系列的指令，这样电脑才算运行起来。\n \n 让我们来看下面的这张图，这是十分完整的计算机组成结构：\n \n-##  Components of a Computer\n+## Components of a Computer\n \n ![Components of a Computer](https://s2.loli.net/2023/04/24/Fzb3uHQBLTlqOgD.png)\n \n 我们可以从中看到在 CPU 需要运行一个进程的时候，首先会将指令告诉主存（main memory）, 然后开始在主存中找地址（Address）找到后加载到在 CPU 内部通用寄存器（register）然后开始执行\n@@ -36,9 +36,8 @@\n 因此，如果我们可以提升主存的速度，那么对于系统来说将会获得很大的性能提升。但我们试图提升主存的速度和容量，又期望其成本很低，这就有点难为人了。因此，我们有一种折中的方法，那就是制作一块速度极快但是容量极小的存储设备。那么其成本也不会太高。这块存储设备我们称之为 `cache`。在硬件上，我们将 `cache` 放置在 `CPU` 和 `主存` 之间，作为主存数据的缓存。当 CPU 试图从主存中 load/store 数据的时候， CPU 会首先从 cache 中查找对应地址的数据是否缓存在 cache 中。如果其数据缓存在 cache 中，直接从 cache 中拿到数据并返回给 CPU。\n \n ![add-cache.png](https://s2.loli.net/2023/04/24/qLhOmsTV2IE9S8p.png)\n \n-\n 其实类比的话，我蛮喜欢 CS 61 c 里面的 Library Analogy，而我自己的想法是有点像现在的物流运输：对一些物品都有一个 `主要的仓库`，而也有一些 `本地仓`，当我要送东西的时候我先去看看 `本地仓` 有没有，没有就再去 `主仓` 去看看，但时间上就没有本地仓的快\n \n > [[2. Areas/01 Blog/03-ComputerSystems/cs61c/SRAM vs. DRAM vs. Disk]]\n \n@@ -49,18 +48,21 @@\n \n ## Cache\n \n ### Cache 的级别\n+>\n > 每一级的 cache 就是每一个下级内存的副本\n \n Cahe 的速度在一定程度上同样影响着系统的性能. 当 cache 中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中 load 数据。为了进一步提升性能，引入多级 cache。前面提到的 cache，称之为 L 1 cache（第一级 cache）。我们在 L 1 cache 后面连接 L 2 cache，在 L 2 cache 和主存之间连接 L 3 cache。等级越高，速度越慢，容量越大。\n \n ### Temporal Locality (时间局部性)\n+>\n > If a memory location is referenced then it will tend to be referenced again soon\n \n 比如说我用过一次这个地址, 我保存起来以防我下次使用\n \n ### Spatial Locality (空间局部性)\n+>\n > If a memory location is referenced, the locations with nearby addresses will\n    Tend to be referenced soon\n \n 比如一个数组，在我读取的时候它会把数组左右的都读取了\n@@ -69,17 +71,19 @@\n \n 在我要对数据进行查找的时候会出现两种情况 `Cache Hit` & `Cache Miss`.\n \n #### Cache hit\n+\n 你要查找的数据 `在缓存中` 从缓存中检索数据并将其带到处理器.\n \n #### Cache miss\n+\n 你要查找的数据 `不在缓存中` 去内存中找数据，把数据放到缓存中，带到处理器中\n \n ## Cache 的工作原理\n \n 现在我们来继续说一些快取的工作原理, 在此之前先来说一下的一些名词\n-\t什么是 `line/tag/index/offset/valid`\n+ 什么是 `line/tag/index/offset/valid`\n \n - **line:** 我们将 cache 平均分成相等的很多块，每一个块大小称之为 `cache line` 也可以叫 `cache block`，其大小是 `cache line size`。\n - **tag:** Used to identify the data (用于识别数据)。每条 Cache Line 前都会有一个独立分配的内存来存 tag，其就是内存地址的前 Nbits。\n $$ addressbits -  offsetbits $$\n@@ -87,12 +91,10 @@\n $$ offset = log_2(line size) $$\n - **index:** 内存地址后续的 bits 则是在这--Way 的是 Cache Line 索引，可以索引 Cache Line。\n - **Valid bit:** Tells you if the data stored at a given cache line is valid (告诉您存储在给定缓存行中的数据是否有效)\n \n-\n > 一个地址访问要映射到 Cache 中，地址被分成三个字段：tag，set index, block offset。这样，通过一个物理地址就可以获取数据或指令在缓存中的位置 (set, way, byte))\n \n-\n ![line-block.png](https://s2.loli.net/2023/04/24/mHdMoveGWXkiNL4.png)\n \n ### Direct mapped cache (直接映射缓存)\n \n@@ -107,8 +109,9 @@\n \n ![Direct Mapped-cache.png](https://s2.loli.net/2023/04/24/4EYI7Va1S5lKgow.png)\n \n ### Two-way set associative cache (两路组相连缓存)\n+\n **Cache 分了 2 组**\n \n 优点: 减少 cache 颠簸出现频率\n > 组相联映射实际上是直接映射和全相联映射的折中方案\n@@ -116,9 +119,8 @@\n 缺点: 增加硬件设计复杂读、成本较高 (需要比较多个 cache line 的 TAG)\n \n ![set associative-cache.png](https://s2.loli.net/2023/04/24/yXE8J6RMo9F3Vxq.png)\n \n-\n ### Fully Associative Cache (全相连缓存)\n \n 优点: 最大程度的降低 cache 颠簸的频率\n >只适合于**小容量**Cache\n@@ -127,9 +129,8 @@\n \n 扩展：[[More Eviction Policies]]\n ![](https://s2.loli.net/2023/07/10/TRUdXNBPsveZS7D.png)\n \n-\n ![Fully Associative.png](https://s2.loli.net/2023/04/24/76uSATyrPno1eYf.png)\n \n 寻找 Hit 的电路\n \n@@ -143,5 +144,4 @@\n \n 三个 cache 的区别之分\n ![Comparisons](https://s2.loli.net/2023/04/24/iICnWkpOMcFtKZH.png)\n **需补充**\n-\n"
                },
                {
                    "date": 1715560844542,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n ---\n title: \"Cache Notes\"\n date: 2024-05-13T08:39:14+08:00\n-draft: true\n+draft: false\n taps: []\n categories: []\n author: [\"Yeelight\"]\n showtoc: true\n@@ -11,9 +11,9 @@\n readingTime: true\n ---\n \n \n-*资料来源: cs 61 c*\n+*资料来源: cs61c*\n \n > Cache 可以说是计算机技术革命中最伟大的想法了\n \n 想一个问题：在我们的电脑里，指令是怎么控制内存里的东西的？因为我们要运行电脑除了 CPU 以外我们要向外 `拿取` 数据才能执行一系列的指令，这样电脑才算运行起来。\n"
                },
                {
                    "date": 1715560849824,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,9 @@\n ---\n title: \"Cache Notes\"\n date: 2024-05-13T08:39:14+08:00\n draft: false\n-taps: []\n+taps: [cache]\n categories: []\n author: [\"Yeelight\"]\n showtoc: true\n weight:\n"
                },
                {
                    "date": 1715560855874,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,10 +1,10 @@\n ---\n title: \"Cache Notes\"\n date: 2024-05-13T08:39:14+08:00\n draft: false\n-taps: [cache]\n-categories: []\n+taps: ['cache']\n+categories: [\"\"]\n author: [\"Yeelight\"]\n showtoc: true\n weight:\n math: false\n"
                },
                {
                    "date": 1715560872949,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n title: \"Cache Notes\"\n date: 2024-05-13T08:39:14+08:00\n draft: false\n taps: ['cache']\n-categories: [\"\"]\n+categories: [\"CS\"]\n author: [\"Yeelight\"]\n showtoc: true\n weight:\n math: false\n"
                }
            ],
            "date": 1715560768088,
            "name": "Commit-0",
            "content": "---\ntitle: \"Cache Notes\"\ndate: 2024-05-13T08:39:14+08:00\ndraft: true\ntaps: []\ncategories: []\nauthor: [\"Yeelight\"]\nshowtoc: true\nweight:\nmath: false\nreadingTime: true\n---\n"
        }
    ]
}